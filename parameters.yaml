train:
  cfg: models/architecture/yolov5n.yaml  # model.yaml path
  weights: models/weights/yolov5n.pt  # initial weights path
  hyp: hyps/hyp.no-augmentation.yaml  # hyperparameters path
  init_batch_size: []  # intial batch size for the first rounds
  final_batch_size: 16  # total final batch size for all GPUs, -1 for autobatch
  init_epochs: []  # total training epochs
  final_epochs: 30
  patience: 5   # EarlyStopping patience (epochs without improvement)
  freeze: [10]   # Freeze layers: backbone=10, 24 for all but the final one 
  seed: 733   # global training seed parameter
  imgsz: 640  # train, val image size (pixels)
  resume: False   # resume most recent training
  nosave: False   # only save final checkpoint
  noval: False   # only validate final epoch
  noplots: True   # save no plot files
  single_cls: False   # train multi-class data as single-class
  optimizer: SGD  # optimizer
  cos_lr: False   # cosine LR scheduler
test:
  batch_size: 16  # batch size
  imgsz: 640  # inference size (pixels)
  conf_thres: 0.001   # confidence threshold
  iou_thres: 0.6   # NMS IoU threshold
  max_det: 300  # maximum detections per image
  task: test  # train, val, test, speed or study
  single_cls: False   # treat as single-class dataset
  half: False   # use FP16 half-precision inference
  augment: False   # augmented inference
  save_txt: False   # save results to *.txt
  save_hybrid: False  # save label+prediction hybrid results to *.txt
  save_conf: False   # save confidences in --save-txt labels
  save_json: False   # save a COCO-JSON results file
  plots: False   # plot the results
detect:
  imgsz: [640, 640]   # inference size (height, width)
  init_conf_thres: []  # confidence thresholds for the first rounds
  final_conf_thres: 0.1  # confidence threshold for the other rounds
  iou_thres: 0.45  # NMS IOU threshold
  max_det: 1000  # maximum detections per image
  view_img: False  # show results
  save_crop: False  # save cropped prediction boxes
  classes: null  # filter by class: --class 0, or --class 0 2 3
  augment: False  # augmented inference
  half: False  # use FP16 half-precision inference
  get_embeddings: True
active learning: 
  n_query: 100 # number of queries per round
  n_rounds: 10 # number of rounds
  val_size: 50  # size of the validation set
  test_size: 100  # size of the validation set
  n_init_labeled: 10  # number of init labeled samples
  n_candidates: 1000   # size of the selection pool
  n_runs: 1  # number of runs
  strategy_name: Hybrid # query strategy
  project: results   # save csv file to project
  weights: best  # take best or last weights
  fine_tune: False  # if False, train from scratch in each round ; if True, use the model of last round
  alpha: 0.8  # if fine-tuning, proportion of new labeled data used for the training
